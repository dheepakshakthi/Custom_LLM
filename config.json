{
  "vocab_size": 50257,
  "dim": 384,             
  "n_layers": 6,           
  "n_heads": 6,            
  "n_kv_heads": 2,         
  "hidden_dim": 1024,      
  "max_seq_len": 256,      
  "batch_size": 2,         
  "gradient_accumulation_steps": 8,  
  "mixed_precision": true,
  "norm_eps": 1e-6,
  "learning_rate": 3e-4,
  "max_epochs": 35,
  "warmup_steps": 1000,
  "weight_decay": 0.1,
  "grad_clip": 1.0,
  "save_checkpoint_every": 1000,
  "eval_every": 500
}
